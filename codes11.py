# -*- coding: utf-8 -*-
"""Codes11.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vL3FCY8ElMQM9RRCtVG-Zh1GXStlvkWI
"""

#Import Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import (accuracy_score, precision_score, recall_score,
                             roc_auc_score, f1_score, classification_report,
                             confusion_matrix)
import shap
from statsmodels.stats.outliers_influence import variance_inflation_factor

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
# Load the dataset
file_path = '/content/drive/MyDrive/ulip_lapse_dataset_12.csv'
df = pd.read_csv('/content/drive/MyDrive/ulip_lapse_dataset_12.csv')

df = pd.read_csv('/content/drive/MyDrive/ulip_lapse_dataset_12.csv')

print(df.isnull().sum())

print(df.info())

df.duplicated().sum()

df.describe()

"""EXPLANATORY ANALYSIS"""

#Count the number of policies for each Lapse Flag
lapse_counts = df['Lapse flag'].value_counts()
print(lapse_counts)
# Lapse flag distribution
lapse_counts.plot(kind='bar',color=['blue','red'])
plt.title('Count of Policies by Lapse flag')
plt.xlabel('Lapse Flag (0 = Active, 1 = Lapsed)')
plt.ylabel('Number of policies')
plt.show()

# Numeric feature
num_features = ['Age', 'Income(USD)', 'Premium(USD)', 'Fund value(USD)', 'Policy charges']
plt.figure(figsize=(15,10))
for i, feature in enumerate(num_features, 1):
    plt.subplot(3,2,i)
    sns.histplot(data=df, x=feature, hue='Lapse flag', kde=True)
plt.tight_layout()
plt.show()

# Categorical feature
cat_features = ['Gender', 'Employment status', 'Economic condition']
plt.figure(figsize=(15,8))
for i, feature in enumerate(cat_features, 1):
    plt.subplot(2,2,i)
    sns.countplot(data=df, x=feature, hue='Lapse flag')
plt.tight_layout()
plt.show()

df.columns

"""DATA PREPROCESSING"""

# Drop Policy id
df.drop(columns=['Policy id'], inplace=True)

# One-Hot encoding
Policies_encoded = pd.get_dummies(
    df,
    columns=['Gender', 'Employment status', 'Economic condition', 'Premium payment mode', 'Premium frequency'],
    drop_first=True,
    dtype=int
)

print("\nOne-Hot Encoded Policies:")
Policies_encoded.head()

"""Further explanatory data analysis"""

Policies_encoded.describe()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from statsmodels.stats.outliers_influence import variance_inflation_factor

def plot_multicollinearity(Policies_encoded, threshold=5):
    # Calculate correlation matrix
    corr_matrix = Policies_encoded.corr()

    # Plot heatmap
    plt.figure(figsize=(14, 10))
    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f")
    plt.title('Correlation Matrix')
    plt.show()

    # Calculate VIF scores
    vif_data = pd.DataFrame()
    vif_data["feature"] = Policies_encoded.columns
    Policies_encoded_numeric = Policies_encoded.apply(pd.to_numeric, errors='coerce').fillna(0)
    vif_data["VIF"] = [variance_inflation_factor(Policies_encoded_numeric.values, i) for i in range(Policies_encoded_numeric.shape[1])]

    # Print VIF scores above threshold
    print("VIF Scores above threshold:")
    print(vif_data[vif_data["VIF"] > threshold])

    return vif_data
# Generate plot
vif_results = plot_multicollinearity(Policies_encoded)

# Show detailed results
print(vif_results)

#Save the new dataset
Policies_encoded.to_csv('Policydata1.csv', index =False)
print("Policydata1:")
Policydata1 = pd.read_csv('Policydata1.csv')
Policydata1.head()

#Feature selection
import pandas as pd
from sklearn.feature_selection import SelectKBest, f_regression
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
#Define of the target variable and feature set
X=Policydata1.drop(columns=['Lapse flag'])
y=Policydata1['Lapse flag']
y.head()

print(X.shape, y.shape)

# Split the data into training and testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)
print(X_train.shape, X_test.shape,y_train.shape,y_test.shape)

#Apply SlectKBest with f_regression
selector = SelectKBest(score_func=f_regression, k='all')
#Fit the selector on the training data
selector.fit(X_train, y_train)
#The top K features
feature_score = selector.scores_
p_values = selector.pvalues_

#Create a dataframe
feature_score_df = pd.DataFrame({'Feature': X.columns, 'F-Score': feature_score, 'P-value': p_values})
feature_score_df = feature_score_df.sort_values(by='F-Score', ascending =False)
print(feature_score_df)

#Using the MinMaxScaler for normalization of data
from sklearn.preprocessing import MinMaxScaler
#Create a MinMax object
scaler = MinMaxScaler()

#Normalize the data
normalized_Policydata1 = scaler.fit_transform(Policydata1)
print("Normalized Policydata1")
print(normalized_Policydata1)

import pandas as pd
from sklearn.model_selection import train_test_split

# X = features, y = target
X = Policydata1.drop("Lapse flag", axis=1)
y = Policydata1["Lapse flag"]

#Data splitting into training and temporary set
X_train, X_temp, y_train, y_temp = train_test_split(X, y, train_size=3750, random_state=42)

#Data splitting into temporary set into test and validation
X_test, X_check, y_test, y_check = train_test_split(X_temp, y_temp, train_size=1100, random_state=42)

#Output the splits
print("Training features shape:", X_train.shape)
print("Test features shape:", X_test.shape)
print("Validation features shape:", X_check.shape)
print("Training labels shape:", y_train.shape)
print("Test labels shape:", y_test.shape)
print("Validation labels shape:", y_check.shape)

#Normalize data (fit on train, transform on train/test)
scaler = MinMaxScaler()
X_train_normalized = scaler.fit_transform(X_train)
X_test_normalized = scaler.transform(X_test)

"""LOGISTIC REGRESSION"""

#Logistic Regression
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score,classification_report,confusion_matrix
#Initializing the model
lrmodel = LogisticRegression(max_iter=200)
#Fit and training the model
lrmodel.fit(X_train, y_train)

# Generate predictions
y_pred = lrmodel.predict(X_test)
print("Predicted values:",y_pred)

#Evaluation of the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy * 100: .2f}%")

#Detailed classsification report
print("\nLogistic Regression Classification Report:")
print(classification_report(y_test, y_pred))

#Confusion Matrix
print("\nLogistic Regression Confusion_Matrix:")
print(confusion_matrix(y_test,y_pred))

from sklearn.metrics import confusion_matrix, classification_report
# Generating the confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Plotting the confusion matrix
plt.figure(figsize=(10, 7))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=np.unique(y_test),
            yticklabels=np.unique(y_test))
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

"""XG Boost with class balancing"""

# Import required libraries
import xgboost as xgb
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline
import matplotlib.pyplot as plt
import seaborn as sns

# Calculate class weights for imbalance handling
class_counts = np.bincount(y_train)
scale_pos_weight = class_counts[0] / class_counts[1]

# Create pipeline with SMOTE and XGBoost
model = ImbPipeline([
    ('smote', SMOTE(random_state=42)),
    ('xgb', xgb.XGBClassifier(
        objective='binary:logistic',
        eval_metric='logloss',
        use_label_encoder=False,
        early_stopping_rounds=10,
        max_depth=3,
        learning_rate=0.1,
        subsample=0.8,
        colsample_bytree=0.8,
        gamma=0.1,
        reg_alpha=0.5,
        reg_lambda=0.5,
        scale_pos_weight=scale_pos_weight,
        random_state=42
    ))
])

# Train with validation-based early stopping
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.22, random_state=42)
model.fit(
    X_train, y_train,
    xgb__eval_set=[(X_val, y_val)],
    xgb__verbose=False
)

# Generate predictions
y_pred = model.predict(X_test)
y_proba = model.predict_proba(X_test)[:, 1]

# Performance evaluation
print("Anti-Overfit XGBoost with Class Balancing")
print(f"Test Accuracy: {accuracy_score(y_test, y_pred):.2f}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred, zero_division=0))

# Confusion matrix visualization
plt.figure(figsize=(8,6))
sns.heatmap(confusion_matrix(y_test, y_pred),
            annot=True, fmt='d', cmap='Blues',
            xticklabels=np.unique(y_test),
            yticklabels=np.unique(y_test))
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""ANN"""

!pip install tensorflow
# Import necessary libraries
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# Build the ANN model
ann_model = keras.Sequential([
    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
    layers.Dense(64, activation='relu'),
    layers.Dense(1, activation='sigmoid')
])
print(ann_model)

# Compile the model
ann_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Fit the model
ann_model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1)

# Make predictions
ann_predictions = (ann_model.predict(X_test) > 0.5).astype("int32")

# Evaluate the model
print("ANN Classifier Accuracy:", accuracy_score(y_test, ann_predictions))
print(classification_report(y_test, ann_predictions))

# Generating the confusion matrix
cm = confusion_matrix(y_test, ann_predictions)

"""ROC-AUC CURVE"""

# Get predicted probabilities for each model
xgb_probs = best_xgb.predict_proba(X_test)[:, 1]
ann_probs = model.predict_proba(X_test)[:, 1]
logistic_probs = lrmodel.predict_proba(X_test)[:, 1]

# Calculate ROC curve and AUC for each model
from sklearn.metrics import roc_curve, auc
fpr_xgb, tpr_xgb, _ = roc_curve(y_test, xgb_probs)
roc_auc_xgb = auc(fpr_xgb, tpr_xgb)

fpr_ann, tpr_ann, _ = roc_curve(y_test, ann_probs)
roc_auc_ann = auc(fpr_ann, tpr_ann)

fpr_logistic, tpr_logistic, _ = roc_curve(y_test, logistic_probs)
roc_auc_logistic = auc(fpr_logistic, tpr_logistic)

plt.figure(figsize=(10, 8))
plt.plot(fpr_xgb, tpr_xgb, color='blue', label='XGBoost (AUC = {:.2f})'.format(roc_auc_xgb))
plt.plot(fpr_ann, tpr_ann, color='green', label='ANN (AUC = {:.2f})'.format(roc_auc_ann))
plt.plot(fpr_logistic, tpr_logistic, color='orange', label='Logistic Regression (AUC = {:.2f})'.format(roc_auc_logistic))

# Plot the diagonal line
plt.plot([0, 1], [0, 1], color='red', linestyle='--')

# Adding labels and title
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.grid()
plt.show()

# Evaluate the best model
from sklearn.metrics import accuracy_score
xgb_predictions = best_xgb.predict(X_test)

print(f"ANN Classifier Accuracy: {accuracy_score(y_test, ann_predictions)*100:.2f}%")
print(f"Anti-Overfit XGBoost with Class Balancing: {accuracy_score(y_test, y_pred)*100:.2f}%")
print(f"Logistic Accuracy: {accuracy * 100: .2f}%")

import shap
import matplotlib.pyplot as plt

# Access the XGBoost model
xgb_model = best_xgb
transformed_X_val = X_val
your_features = X_val.columns
# SHAP Global Explanation
explainer = shap.TreeExplainer(xgb_model)
shap_values = explainer.shap_values(transformed_X_val)

plt.figure(figsize=(12, 8))
shap.summary_plot(shap_values,
                 transformed_X_val,
                 feature_names=your_features,
                 plot_type='dot',
                 max_display=15,
                 show=False)

plt.title("Lapse Prediction SHAP Analysis", fontsize=14, pad=20)
plt.xlabel("SHAP Value Impact", fontsize=12)
plt.tight_layout()
plt.show()

# Individual Policy Explanation
shap.initjs()
individual_plot = shap.force_plot(
    explainer.expected_value,
    shap_values[0],
    transformed_X_val.iloc[0],
    feature_names=your_features,
    matplotlib=True
)
plt.title("Individual Policy Decision Breakdown", pad=20)
plt.tight_layout()
plt.show()





